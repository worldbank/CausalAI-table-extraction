{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOld0Topopb2",
        "outputId": "484cbb1c-76f0-4cfd-8982-ac698862238c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.24.7)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.6 in /usr/local/lib/python3.10/dist-packages (from pymupdf) (1.24.6)\n"
          ]
        }
      ],
      "source": [
        "pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import fitz\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "B4JOqXUXprON"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_word_positions(pdf_path, page_num):\n",
        "    \"\"\"\n",
        "    Extract word positions from a specified page of a PDF document.\n",
        "\n",
        "    Parameters:\n",
        "    pdf_path (str): The path to the PDF document.\n",
        "    page_num (int): The page number to extract word positions from.\n",
        "\n",
        "    Returns:\n",
        "    df_words (pd.DataFrame): A DataFrame containing word positions and details.\n",
        "    page_width (list): A list containing the width of the page.\n",
        "    \"\"\"\n",
        "    # Open the PDF document\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # List to store word data\n",
        "    word_data = []\n",
        "\n",
        "    # List to store page width\n",
        "    page_width = []\n",
        "\n",
        "    # Load the specified page\n",
        "    page = doc.load_page(page_num)\n",
        "\n",
        "    # Iterate through text blocks on the page\n",
        "    for block in page.get_text(\"dict\", flags=fitz.TEXTFLAGS_TEXT)[\"blocks\"]:\n",
        "        for line in block[\"lines\"]:\n",
        "            # Writing direction = (cosine, sine)\n",
        "            wdir = line[\"dir\"]\n",
        "            # Check if the writing direction is either 90° or 270°\n",
        "            if wdir[0] == 0:\n",
        "                # Add redaction annotation to the line's bounding box\n",
        "                page.add_redact_annot(line[\"bbox\"])\n",
        "\n",
        "    # Apply the redactions (with no image redaction)\n",
        "    page.apply_redactions(images=fitz.PDF_REDACT_IMAGE_NONE)\n",
        "\n",
        "    # Get the width of the page and add to the list\n",
        "    width = page.rect.width\n",
        "    page_width.append(width)\n",
        "\n",
        "    # Get words from the page\n",
        "    words = page.get_text(\"words\")\n",
        "\n",
        "    # Iterate through words and store their positions and other details\n",
        "    for word in words:\n",
        "        x0, y0, x1, y1, word_text, block_no, line_no, word_no = word\n",
        "        word_data.append([page_num, x0, y0, x1, y1, word_text, block_no, line_no, word_no])\n",
        "\n",
        "    # Create a DataFrame from the word data\n",
        "    df_words = pd.DataFrame(word_data, columns=[\"page_num\", \"x0\", \"y0\", \"x1\", \"y1\", \"word_text\", \"block_no\", \"line_no\", \"word_no\"])\n",
        "\n",
        "    return df_words, page_width\n",
        "\n",
        "\n",
        "\n",
        "def merge_words_into_lines(df_words, page_widths, y_threshold=5):\n",
        "    \"\"\"\n",
        "    Merge words into lines based on their vertical positions.\n",
        "\n",
        "    Parameters:\n",
        "    df_words (pd.DataFrame): DataFrame containing word positions and details.\n",
        "    page_widths (list): List containing the width of each page.\n",
        "    y_threshold (int): Threshold for merging words into the same line based on vertical position.\n",
        "\n",
        "    Returns:\n",
        "    df_lines (pd.DataFrame): DataFrame containing merged lines.\n",
        "    flagged_lines (list): List of line numbers where all words are in the left half of the page.\n",
        "    \"\"\"\n",
        "    # Sort the DataFrame by page number, vertical position, and horizontal position\n",
        "    df_words = df_words.sort_values(by=[\"page_num\", \"y0\", \"x0\"]).reset_index(drop=True)\n",
        "\n",
        "    # Initialize lists to store lines and current line information\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    current_line_num = 0\n",
        "\n",
        "    # Iterate through the words\n",
        "    for i, row in df_words.iterrows():\n",
        "        if not current_line:\n",
        "            # Start a new line with the current word if no current line exists\n",
        "            current_line.append(row)\n",
        "        else:\n",
        "            prev_word = current_line[-1]\n",
        "            # Check if the current word is on the same line as the previous word\n",
        "            if row[\"page_num\"] == prev_word[\"page_num\"] and abs(row[\"y0\"] - prev_word[\"y0\"]) <= y_threshold:\n",
        "                current_line.append(row)\n",
        "            else:\n",
        "                # Append the current line to lines and start a new line\n",
        "                lines.append((current_line_num, current_line))\n",
        "                current_line = [row]\n",
        "                current_line_num += 1\n",
        "\n",
        "    # Append the last line if it exists\n",
        "    if current_line:\n",
        "        lines.append((current_line_num, current_line))\n",
        "\n",
        "    # Initialize lists to store line data and flagged lines\n",
        "    line_data = []\n",
        "    flagged_lines = []\n",
        "\n",
        "    # Iterate through lines to create line data and flag lines\n",
        "    for line_num, words in lines:\n",
        "        page_num = words[0][\"page_num\"]\n",
        "        x = page_widths[page_num] / 10  # Calculate x threshold as 1/10th of the page width\n",
        "        # Check if all words in the line are in the left half of the page\n",
        "        if all(word[\"x0\"] < 5 * x for word in words):\n",
        "            flagged_lines.append(line_num)\n",
        "        # Add word data to line data\n",
        "        for word in words:\n",
        "            line_data.append([line_num, word[\"x0\"], word[\"y0\"], word[\"x1\"], word[\"y1\"], word[\"word_text\"]])\n",
        "\n",
        "    # Create a DataFrame from the line data\n",
        "    df_lines = pd.DataFrame(line_data, columns=[\"line_num\", \"x0\", \"y0\", \"x1\", \"y1\", \"word_text\"])\n",
        "\n",
        "    return df_lines, flagged_lines\n",
        "\n",
        "def find_lines_with_large_x_diff(df_lines, threshold=50):\n",
        "    lines_with_large_diff = df_lines[df_lines[\"distance\"] > threshold][\"line_num\"].unique()\n",
        "    return lines_with_large_diff\n",
        "\n",
        "# Function to calculate distances between words in the same line\n",
        "def calculate_distances(df):\n",
        "    distances = []\n",
        "\n",
        "    # Group by line_num\n",
        "    grouped = df.groupby('line_num')\n",
        "\n",
        "    for line_num, group in grouped:\n",
        "        group = group.sort_values('x0')\n",
        "        previous_x1 = None\n",
        "\n",
        "        for index, row in group.iterrows():\n",
        "            if previous_x1 is not None:\n",
        "                distance = row['x0'] - previous_x1\n",
        "                distance = round(distance)\n",
        "                distances.append({\n",
        "                    'line_num': line_num,\n",
        "                    'word1': previous_word,\n",
        "                    'word2': row['word_text'],\n",
        "                    'distance': distance\n",
        "                })\n",
        "            previous_x1 = row['x1']\n",
        "            previous_word = row['word_text']\n",
        "\n",
        "    return pd.DataFrame(distances)\n",
        "\n",
        "def union_of_lists(list1, list2):\n",
        "    # Convert lists to sets and perform union\n",
        "    union_set = set(list1) | set(list2)\n",
        "    # Convert the set back to a list (optional, as sets can be used directly)\n",
        "    union_list = list(union_set)\n",
        "    return union_list\n",
        "\n",
        "def consecutive_sublists(lst, min_length=3):\n",
        "    lst = sorted(lst)\n",
        "    sublists = []\n",
        "    current_sublist = []\n",
        "\n",
        "    for num in lst:\n",
        "        if not current_sublist or num == current_sublist[-1] + 1:\n",
        "            current_sublist.append(num)\n",
        "        else:\n",
        "            if len(current_sublist) >= min_length:\n",
        "                sublists.append(current_sublist)\n",
        "            current_sublist = [num]\n",
        "\n",
        "    if len(current_sublist) >= min_length:\n",
        "        sublists.append(current_sublist)\n",
        "\n",
        "    return sublists\n",
        "\n",
        "def check_y_diff_within_threshold_text_classification(df, sublist, threshold=45):\n",
        "    # Filter the dataframe for the lines in the sublist\n",
        "    filtered_df = df[df['line_num'].isin(sublist)]\n",
        "\n",
        "    # Get the first entry per line number\n",
        "    first_entries_per_line = filtered_df.groupby('line_num').first().reset_index()\n",
        "\n",
        "    # Extract the y0 values\n",
        "    y0_values = first_entries_per_line['y0'].values\n",
        "    # Check differences and remove elements if needed\n",
        "    while True:\n",
        "        y_diff = abs(pd.Series(y0_values).diff().dropna())\n",
        "        y_diff = y_diff.tolist()\n",
        "        if len(y_diff) > 0:\n",
        "          y_diff.insert(0, y_diff[0])\n",
        "        y_diff = pd.Series(y_diff)\n",
        "\n",
        "        exceed_indices = y_diff[y_diff > threshold].index\n",
        "        if exceed_indices.empty:\n",
        "            return True\n",
        "\n",
        "        # Remove the element causing the exceedance\n",
        "        exceed_index = exceed_indices[0]  # Adjust for the dropped first value\n",
        "\n",
        "        y0_values = list(y0_values)\n",
        "\n",
        "        del y0_values[exceed_index]\n",
        "\n",
        "        if len(y0_values) <= 2:\n",
        "            return False  # If there are fewer than 2 elements, we can't compare\n",
        "\n",
        "def get_y0(df, sublist):\n",
        "    # Filter the dataframe for the lines in the sublist\n",
        "    filtered_df = df[df['line_num'].isin(sublist)]\n",
        "\n",
        "    # Get the first entry per line number\n",
        "    first_entries_per_line = filtered_df.groupby('line_num').first().reset_index()\n",
        "    #print(first_entries_per_line)\n",
        "\n",
        "    # Extract the y0 values\n",
        "    y0_values = first_entries_per_line['y0'].values\n",
        "    y1_values = first_entries_per_line['y1'].values\n",
        "    return (y0_values[0], y1_values[-1])\n",
        "\n",
        "def get_pdf_page_dimensions(pdf_path, page_number = 5):\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    # Select the specific page\n",
        "    page = pdf_document.load_page(page_number)\n",
        "\n",
        "    # Get the dimensions\n",
        "    width = page.rect.width\n",
        "    height = page.rect.height\n",
        "\n",
        "    return width, height\n",
        "\n",
        "def calculate_overlap(region, range_header, range_footnote):\n",
        "    header_start, header_end = range_header\n",
        "    footnote_start, footnote_end = range_footnote\n",
        "    region_start, region_end = region\n",
        "\n",
        "    # Calculate overlap with header\n",
        "    header_overlap = max(0, min(region_end, header_end) - max(region_start, header_start))\n",
        "\n",
        "    # Calculate overlap with footnote\n",
        "    footnote_overlap = max(0, min(region_end, footnote_end) - max(region_start, footnote_start))\n",
        "\n",
        "    # Total overlap\n",
        "    total_overlap = max(header_overlap, footnote_overlap)\n",
        "\n",
        "    # Calculate the length of the figure region\n",
        "    region_length = region_end - region_start\n",
        "\n",
        "    # Calculate the percentage of overlap\n",
        "    overlap_percentage = (total_overlap / region_length) * 100\n",
        "\n",
        "    return overlap_percentage\n",
        "\n",
        "def filter_regions(regions, range_header, range_footnote, threshold=50):\n",
        "    filtered_regions = []\n",
        "\n",
        "    for region in regions:\n",
        "        overlap_percentage = calculate_overlap(region, range_header, range_footnote)\n",
        "        if overlap_percentage <= threshold:\n",
        "            filtered_regions.append(region)\n",
        "\n",
        "    return filtered_regions\n",
        "\n",
        "\n",
        "def pymupdf_extract_blocks_with_coords(page, adjusted_bbox_matrix):\n",
        "\n",
        "    x_pdf = adjusted_bbox_matrix[0][0]\n",
        "    y_pdf = adjusted_bbox_matrix[0][1]\n",
        "    x_pdf_2 = adjusted_bbox_matrix[0][2]\n",
        "    y_pdf_2 = adjusted_bbox_matrix[0][3]\n",
        "\n",
        "    #pdf_document = fitz.open(pdf_path)\n",
        "    text_blocks = []\n",
        "    x0_list = []\n",
        "    y0_list = []\n",
        "    x1_list = []\n",
        "    y1_list = []\n",
        "\n",
        "    #page = pdf_document.load_page(page_num)\n",
        "\n",
        "    words = page.get_text(\"words\")\n",
        "\n",
        "    current_block = []\n",
        "    for word in words:\n",
        "        #print(word)\n",
        "        if x_pdf < word[0] < x_pdf_2 and y_pdf < (word[1] + word [3])/2 < y_pdf_2:\n",
        "            if not current_block:  # If the current_block is empty, this is the first word that meets the condition.\n",
        "                current_block = [word]\n",
        "            else:\n",
        "                previous_word = current_block[-1]\n",
        "                current_word = word\n",
        "\n",
        "                # Calculate horizontal distance and vertical alignment difference\n",
        "                distance_x = current_word[0] - previous_word[2]\n",
        "                alignment_y = abs((current_word[1] + current_word[3]) - (previous_word[1] + previous_word[3])) / 2\n",
        "\n",
        "                if 0 < distance_x < 1 and alignment_y < 1:\n",
        "                    current_block.append(current_word)\n",
        "                else:\n",
        "                    # For each block, store the text and coordinates\n",
        "                    text_blocks.append(' '.join([w[4] for w in current_block]))\n",
        "                    x0_list.append(current_block[0][0])\n",
        "                    y0_list.append(current_block[0][1])\n",
        "                    x1_list.append(current_block[-1][2])\n",
        "                    y1_list.append(current_block[-1][3])\n",
        "\n",
        "                    current_block = [current_word]\n",
        "\n",
        "    # Handle the last block in the page\n",
        "    if current_block:\n",
        "        text_blocks.append(' '.join([w[4] for w in current_block]))\n",
        "        x0_list.append(current_block[0][0])\n",
        "        y0_list.append(current_block[0][1])\n",
        "        x1_list.append(current_block[-1][2])\n",
        "        y1_list.append(current_block[-1][3])\n",
        "\n",
        "    #pdf_document.close()\n",
        "    return text_blocks, x0_list, y0_list, x1_list, y1_list\n",
        "\n",
        "def find_unique_lines_row(df):\n",
        "    # Calculate heights and their mean\n",
        "    heights = [row['Y1'] - row['Y0'] for i, row in df.iterrows()]\n",
        "    height_mean = sum(heights) / len(heights)\n",
        "\n",
        "    # Initialize list to keep track of unique lines\n",
        "    h_lines = []\n",
        "    sensitivity = height_mean / 1.6\n",
        "\n",
        "    # Identify unique lines based on sensitivity\n",
        "    for y0 in df['Y0']:\n",
        "        found = False\n",
        "        for c in h_lines:\n",
        "            if abs(y0 - c) < sensitivity:\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            h_lines.append(y0)\n",
        "\n",
        "    return h_lines\n",
        "\n",
        "def find_unique_lines_column(df):\n",
        "    # Calculate heights and their mean\n",
        "    heights = [row['X1'] - row['X0'] for i, row in df.iterrows()]\n",
        "    height_mean = sum(heights) / len(heights)\n",
        "\n",
        "    # Initialize list to keep track of unique lines\n",
        "    h_lines = []\n",
        "    sensitivity = height_mean / 2\n",
        "\n",
        "    # Identify unique lines based on sensitivity\n",
        "    for y0 in df['X0']:\n",
        "        found = False\n",
        "        for c in h_lines:\n",
        "            if abs(y0 - c) < sensitivity:\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            h_lines.append(y0)\n",
        "\n",
        "    return h_lines\n",
        "\n",
        "def find_segment(midpoint, lines):\n",
        "    \"\"\"Helper function to determine the segment number based on the midpoint.\"\"\"\n",
        "    for i, line in enumerate(lines):\n",
        "        if midpoint < line:\n",
        "            return i\n",
        "    return len(lines)  # for the last segment\n",
        "\n",
        "def assign_row_col_numbers(df, row_lines, column_lines):\n",
        "    # Calculate midpoints\n",
        "    df['MidX'] = (df['X0'] + df['X1']) / 2\n",
        "    df['MidY'] = (df['Y0'] + df['Y1']) / 2\n",
        "\n",
        "    # Determine row and column numbers\n",
        "    df['RowNumber'] = df['MidY'].apply(lambda y: find_segment(y, row_lines))\n",
        "    df['ColumnNumber'] = df['MidX'].apply(lambda x: find_segment(x, column_lines))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "L4UZGcEvowLY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"add_your_pdf_path_here.pdf\""
      ],
      "metadata": {
        "id": "Pc4Ho_t-pqfg"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list the page numbers where the table contains in the document. Page number always start with zero.\n",
        "page_numbers = [0]"
      ],
      "metadata": {
        "id": "Yvm0x8nSp3PU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_dfs = []  # Initialize an empty list to store dataframes for each page\n",
        "\n",
        "# Iterate through each page number in the list of page numbers\n",
        "for number_page in page_numbers:\n",
        "\n",
        "    number_page = int(number_page)  # Convert page number to integer\n",
        "\n",
        "\n",
        "    # Extract word positions from the given PDF page\n",
        "    df_words, page_widths = extract_word_positions(pdf_path, page_num=number_page)\n",
        "\n",
        "    # Merge words into lines based on their positions\n",
        "    df_lines, flagged_lines = merge_words_into_lines(df_words, page_widths)\n",
        "\n",
        "    # Calculate distances between lines to identify potential breaks\n",
        "    distances_df = calculate_distances(df_lines)\n",
        "    text_lines = find_lines_with_large_x_diff(distances_df)  # Find lines with significant x-difference\n",
        "    result = union_of_lists(flagged_lines, list(text_lines))  # Combine flagged lines and text lines\n",
        "    result.sort()\n",
        "\n",
        "    # Create sublists of consecutive lines\n",
        "    result_sublists = consecutive_sublists(result)\n",
        "\n",
        "    # Filter sublists based on y-difference threshold for text classification\n",
        "    for sublist in result_sublists:\n",
        "        result = check_y_diff_within_threshold_text_classification(df_lines, sublist, threshold=60)\n",
        "        if not result:\n",
        "            del result_sublists[result_sublists.index(sublist)]\n",
        "\n",
        "    # Get PDF page dimensions\n",
        "    width, height = get_pdf_page_dimensions(pdf_path, page_number=number_page)\n",
        "    footnote_start = height - height/10  # Define footnote region start\n",
        "    footnote_end = height  # Define footnote region end\n",
        "    range_footnote = [footnote_start, footnote_end]\n",
        "    range_header = [0, height/10]  # Define header region\n",
        "\n",
        "    # Get bounding boxes for sublists\n",
        "    result_sublist_bbox = []\n",
        "    for sublist in result_sublists:\n",
        "        result = get_y0(df_lines, sublist)\n",
        "        result_sublist_bbox.append(result)\n",
        "\n",
        "    # Filter regions to exclude header and footnote regions\n",
        "    new_result_sublist_bbox = filter_regions(result_sublist_bbox, range_header, range_footnote)\n",
        "    new_result_sublist_bbox = sorted(new_result_sublist_bbox, key=lambda x: x[0], reverse=False)\n",
        "\n",
        "    # Extract text blocks within the filtered bounding boxes\n",
        "    for region in new_result_sublist_bbox:\n",
        "        x0, y0, x1, y1 = page_widths[0]*0.04, region[0], page_widths[0]*0.96, region[1]  # Define adjusted bounding box\n",
        "        adjusted_bbox_matrix = [[x0, y0, x1, y1]]\n",
        "        doc = fitz.open(pdf_path)  # Open the PDF document\n",
        "        page = doc.load_page(number_page)  # Load the specific page\n",
        "        text_blocks, x0_list, y0_list, x1_list, y1_list = pymupdf_extract_blocks_with_coords(page, adjusted_bbox_matrix)  # Extract text blocks with coordinates\n",
        "\n",
        "        # Create a DataFrame with the extracted text blocks and their coordinates\n",
        "        data = {\n",
        "            'Text': text_blocks,\n",
        "            'X0': x0_list,\n",
        "            'Y0': y0_list,\n",
        "            'X1': x1_list,\n",
        "            'Y1': y1_list\n",
        "        }\n",
        "        new_df = pd.DataFrame(data)\n",
        "\n",
        "        # Make a copy of the DataFrame\n",
        "        df_new = new_df.copy()\n",
        "        row_lines = find_unique_lines_row(df_new)  # Find unique row lines\n",
        "        row_lines.sort()\n",
        "\n",
        "        column_lines = find_unique_lines_column(df_new)  # Find unique column lines\n",
        "        column_lines.sort()\n",
        "\n",
        "        updated_df = assign_row_col_numbers(df_new, row_lines, column_lines)  # Assign row and column numbers to the DataFrame\n",
        "\n",
        "        # Group by RowNumber and ColumnNumber and concatenate texts\n",
        "        grouped = df_new.groupby(['RowNumber', 'ColumnNumber'])['Text'].agg(' '.join).reset_index()\n",
        "\n",
        "        # Pivot the DataFrame to create a mapped view\n",
        "        mapped_df = grouped.pivot(index='RowNumber', columns='ColumnNumber', values='Text')\n",
        "\n",
        "        # Fill NaN with empty strings if needed\n",
        "        mapped_df = mapped_df.fillna('')\n",
        "\n",
        "        # Combine the first row to form a single header\n",
        "        new_header = mapped_df.iloc[0:1].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=0)\n",
        "        mapped_df.columns = new_header  # Set the new header\n",
        "        mapped_df = mapped_df[1:]  # Remove the header row from the DataFrame\n",
        "\n",
        "        # Reset index if necessary\n",
        "        mapped_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        main_dfs.append(mapped_df)  # Append the processed DataFrame to the main list\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h0XMsl3Up5JE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the table on first page\n",
        "#main_dfs[0]"
      ],
      "metadata": {
        "id": "Qsa_KuTSvTXC"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovAFe6F0vtW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}